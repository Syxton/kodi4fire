From ae7ef01ad15ea91f669a59d4fd44aa9c03a3a6fb Mon Sep 17 00:00:00 2001
From: Ronnie Sahlberg <ronniesahlberg@gmail.com>
Date: Sat, 7 Feb 2015 11:16:38 -0800
Subject: [PATCH 1/7] Sequential Readahead Mode

Add a new api to activate sequential reading of files.
It is activated by calling nfs_set_streaming_mode(fs,size)
with a filehandle and a size.

Signed-off-by: Ronnie Sahlberg <ronniesahlberg@gmail.com>
---
 include/nfsc/libnfs-raw.h |   9 ++
 include/nfsc/libnfs.h     |  14 +++
 lib/libnfs-sync.c         |  12 ++-
 lib/libnfs-win32.def      |   5 +
 lib/libnfs.c              | 258 +++++++++++++++++++++++++++++++++++++++++++++-
 lib/socket.c              |  15 ++-
 6 files changed, 308 insertions(+), 5 deletions(-)

diff --git a/include/nfsc/libnfs-raw.h b/include/nfsc/libnfs-raw.h
index 3ba9de3..4593cc6 100644
--- a/include/nfsc/libnfs-raw.h
+++ b/include/nfsc/libnfs-raw.h
@@ -44,6 +44,15 @@ int rpc_get_fd(struct rpc_context *rpc);
 int rpc_which_events(struct rpc_context *rpc);
 int rpc_service(struct rpc_context *rpc, int revents);
 char *rpc_get_error(struct rpc_context *rpc);
+
+/* Return the number of PDUs in the outqueue.
+ * This is the count of PDUs not yet written to the socket.
+ */
+int rpc_outqueue_length(struct rpc_context *rpc);
+/* Return the number all in flight PDUs.
+ * This includes both the PDUs not yet written to the socket as well as
+ * all PDUs we have sent to the server but not yet received a reply to.
+ */
 int rpc_queue_length(struct rpc_context *rpc);

 /* Utility function to get an RPC context from a NFS context. Useful for doing low level NFSACL
diff --git a/include/nfsc/libnfs.h b/include/nfsc/libnfs.h
index 2d14113..f84650b 100644
--- a/include/nfsc/libnfs.h
+++ b/include/nfsc/libnfs.h
@@ -83,6 +83,15 @@ struct utimbuf {
 EXTERN int nfs_get_fd(struct nfs_context *nfs);
 EXTERN int nfs_which_events(struct nfs_context *nfs);
 EXTERN int nfs_service(struct nfs_context *nfs, int revents);
+
+/* Return the number of PDUs in the outqueue.
+ * This is the count of PDUs not yet written to the socket.
+ */
+EXTERN int nfs_outqueue_length(struct nfs_context *nfs);
+/* Return the number all in flight PDUs.
+ * This includes both the PDUs not yet written to the socket as well as
+ * all PDUs we have sent to the server but not yet received a reply to.
+ */
 EXTERN int nfs_queue_length(struct nfs_context *nfs);

 /*
@@ -191,6 +200,11 @@ EXTERN void nfs_set_uid(struct nfs_context *nfs, int uid);
 EXTERN void nfs_set_gid(struct nfs_context *nfs, int gid);
 EXTERN void nfs_set_readahead(struct nfs_context *nfs, uint32_t v);

+/* Optimize for sequentianl streaming reads. size is the amount
+ * of buffering.
+ */
+EXTERN int nfs_set_streaming_mode(struct nfsfh *nfsfh, uint32_t size);
+
 /*
  * MOUNT THE EXPORT
  */
diff --git a/lib/libnfs-sync.c b/lib/libnfs-sync.c
index 59911fc..dc696c3 100644
--- a/lib/libnfs-sync.c
+++ b/lib/libnfs-sync.c
@@ -137,9 +137,14 @@ static void wait_for_reply(struct rpc_context *rpc, struct sync_cb_data *cb_data
 static void wait_for_nfs_reply(struct nfs_context *nfs, struct sync_cb_data *cb_data)
 {
	struct pollfd pfd;
-
-	while (!cb_data->is_finished) {
-
+	int available;
+
+	/* loop until the command has completed, and we have written all
+	 * queued PDUs to the socket, and we have read and processed all
+	 * data in the socket receive buffer.
+	 */
+	ioctl(nfs_get_fd(nfs), FIONREAD, &available);
+	while (!cb_data->is_finished || nfs_outqueue_length(nfs) || available) {
		pfd.fd = nfs_get_fd(nfs);
		pfd.events = nfs_which_events(nfs);
		if (poll(&pfd, 1, -1) < 0) {
@@ -152,6 +157,7 @@ static void wait_for_nfs_reply(struct nfs_context *nfs, struct sync_cb_data *cb_
			cb_data->status = -EIO;
			break;
		}
+		ioctl(nfs_get_fd(nfs), FIONREAD, &available);
	}
 }

diff --git a/lib/libnfs-win32.def b/lib/libnfs-win32.def
index 5a0df03..bdfa737 100644
--- a/lib/libnfs-win32.def
+++ b/lib/libnfs-win32.def
@@ -48,6 +48,7 @@ nfs_open
 nfs_open_async
 nfs_opendir
 nfs_opendir_async
+nfs_outqueue_length
 nfs_parse_url_full
 nfs_parse_url_dir
 nfs_parse_url_incomplete
@@ -56,6 +57,7 @@ nfs_pread
 nfs_pread_async
 nfs_pwrite
 nfs_pwrite_async
+nfs_queue_length
 nfs_read
 nfs_read_async
 nfs_readdir
@@ -71,6 +73,7 @@ nfs_set_gid
 nfs_set_tcp_syncnt
 nfs_set_uid
 nfs_set_readahead
+nfs_set_streaming_mode
 nfs_stat
 nfs_stat_async
 nfs_stat64
@@ -205,6 +208,8 @@ rpc_nsm1_unmon_async
 rpc_nsm1_unmonall_async
 rpc_nsm1_simucrash_async
 rpc_nsm1_notify_async
+rpc_outqueue_length
+rpc_queue_length
 rpc_rquota1_null_async
 rpc_rquota1_getquota_async
 rpc_rquota1_getactivequota_async
diff --git a/lib/libnfs.c b/lib/libnfs.c
index f807822..5fc921d 100644
--- a/lib/libnfs.c
+++ b/lib/libnfs.c
@@ -108,12 +108,37 @@ struct nfs_readahead {
        uint32_t cur_ra;
 };

+/* Store streaming cache in blocks of this size */
+#define NFS_STREAM_BUF_SIZE (32768 * 4)
+/* Skip trying to streaming caching for reads greater than this */
+#define NFS_MAX_STREAMING_SIZE (1024 * 1024)
+
+#define BSS_UNUSED  0
+#define BSS_PENDING 1
+#define BSS_VALID   2
+struct nfs_streaming_block {
+       int state;
+       unsigned char *ptr;
+};
+
+struct nfs_streaming_read {
+       uint64_t next_offset;
+       int num_seq;
+
+       int num_blocks; /* number of buffer blocks */
+       uint64_t buf_offset;
+       struct nfs_streaming_block *blocks;
+       unsigned char *buf;
+};
+
 struct nfsfh {
        struct nfs_fh3 fh;
        int is_sync;
        int is_append;
        uint64_t offset;
-       struct nfs_readahead ra;
+
+       struct nfs_streaming_read *sr;
+       struct nfs_readahead ra; /* broken? */
 };

 struct nested_mounts {
@@ -231,6 +256,11 @@ int nfs_get_fd(struct nfs_context *nfs)
	return rpc_get_fd(nfs->rpc);
 }

+int nfs_outqueue_length(struct nfs_context *nfs)
+{
+	return rpc_outqueue_length(nfs->rpc);
+}
+
 int nfs_queue_length(struct nfs_context *nfs)
 {
	return rpc_queue_length(nfs->rpc);
@@ -730,12 +760,52 @@ static void free_nfs_cb_data(struct nfs_cb_data *data)
	free(data);
 }

+int nfs_set_streaming_mode(struct nfsfh *nfsfh, uint32_t size)
+{
+	struct nfs_streaming_read *sr;
+	int i;
+
+	sr = malloc(sizeof(struct nfs_streaming_read));
+	if (sr == NULL) {
+		return -1;
+	}
+	memset(sr, 0, sizeof(struct nfs_streaming_read));
+	sr->num_blocks = size / NFS_STREAM_BUF_SIZE;
+
+	sr->buf = malloc(sr->num_blocks * NFS_STREAM_BUF_SIZE);
+	if (sr->buf == NULL) {
+		free(sr);
+		return -1;
+	}
+	memset(sr->buf, 0, sr->num_blocks * NFS_STREAM_BUF_SIZE);
+
+	sr->blocks = malloc(sr->num_blocks * sizeof(struct nfs_streaming_block))
+;
+	if (sr->blocks == NULL) {
+		free(sr->buf);
+		free(sr);
+		return -1;
+	}
+	for (i = 0; i < sr->num_blocks; i++) {
+		sr->blocks[i].state = BSS_UNUSED;
+		sr->blocks[i].ptr = &sr->buf[i * NFS_STREAM_BUF_SIZE];
+	}
+	nfsfh->sr = sr;
+
+	return 0;
+}
+
 static void free_nfsfh(struct nfsfh *nfsfh)
 {
	if (nfsfh->fh.data.data_val != NULL) {
		free(nfsfh->fh.data.data_val);
		nfsfh->fh.data.data_val = NULL;
	}
+	if (nfsfh->sr != NULL) {
+		free(nfsfh->sr->blocks);
+		free(nfsfh->sr->buf);
+		free(nfsfh->sr);
+	}
	free(nfsfh->ra.buf);
	free(nfsfh);
 }
@@ -2033,6 +2103,8 @@ static void nfs_open_cb(struct rpc_context *rpc, int status, void *command_data,
	nfsfh->fh = data->fh;
	data->fh.data.data_val = NULL;

+	nfs_set_streaming_mode(nfsfh, 200 * NFS_STREAM_BUF_SIZE);
+
	data->cb(0, nfs, nfsfh, data->private_data);
	free_nfs_cb_data(data);
 }
@@ -2252,10 +2324,194 @@ static void nfs_ra_invalidate(struct nfsfh *nfsfh) {
	nfsfh->ra.cur_ra = NFS_BLKSIZE;
 }

+struct stream_cb_data {
+       uint64_t offset;
+       struct nfsfh *nfsfh;
+};
+
+static void nfs_stream_cb(struct rpc_context *rpc, int status, void *command_data, void *private_data)
+{
+	struct stream_cb_data *stream_data = private_data;
+	struct nfsfh *nfsfh = stream_data->nfsfh;
+	READ3res *res;
+	int i;
+
+	assert(rpc->magic == RPC_CONTEXT_MAGIC);
+
+	if (stream_data->offset < nfsfh->sr->buf_offset) {
+		free(stream_data);
+		return;
+	}
+	if (stream_data->offset >= nfsfh->sr->buf_offset + nfsfh->sr->num_blocks * NFS_STREAM_BUF_SIZE) {
+		free(stream_data);
+		return;
+	}
+
+	i = (stream_data->offset - nfsfh->sr->buf_offset) / NFS_STREAM_BUF_SIZE;
+	nfsfh->sr->blocks[i].state = BSS_UNUSED;
+	free(stream_data);
+
+	if (status == RPC_STATUS_ERROR) {
+		return;
+	}
+	if (status == RPC_STATUS_CANCEL) {
+		return;
+	}
+	if (status == RPC_STATUS_SUCCESS) {
+		res = command_data;
+		if (res->status != NFS3_OK) {
+			return;
+		}
+		if (res->READ3res_u.resok.count != NFS_STREAM_BUF_SIZE) {
+			return;
+		}
+		memcpy(nfsfh->sr->blocks[i].ptr,
+			res->READ3res_u.resok.data.data_val,
+			NFS_STREAM_BUF_SIZE);
+		nfsfh->sr->blocks[i].state = BSS_VALID;
+	}
+}
+
+static void prefetch_streaming_blocks(struct nfs_context *nfs, struct nfsfh *nfsfh, uint64_t next_offset, int num_blocks)
+{
+	int i;
+
+	for (i = 0; i < nfsfh->sr->num_blocks && num_blocks; i++) {
+		struct stream_cb_data *stream_data;
+		READ3args args;
+
+		if (nfsfh->sr->blocks[i].state != BSS_UNUSED) {
+			continue;
+		}
+
+		stream_data = malloc(sizeof(struct stream_cb_data));
+		if (stream_data == NULL) {
+			return;
+		}
+		stream_data->offset = i * NFS_STREAM_BUF_SIZE + nfsfh->sr->buf_offset;
+		stream_data->nfsfh = nfsfh;
+
+		nfs_fill_READ3args(&args, nfsfh, stream_data->offset, NFS_STREAM_BUF_SIZE);
+		if (rpc_nfs3_read_async(nfs->rpc, nfs_stream_cb, &args, stream_data) != 0) {
+			free(stream_data);
+			return;
+		}
+
+		nfsfh->sr->blocks[i].state = BSS_PENDING;
+		num_blocks--;
+	}
+}
+
 static int nfs_pread_async_internal(struct nfs_context *nfs, struct nfsfh *nfsfh, uint64_t offset, uint64_t count, nfs_cb cb, void *private_data, int update_pos)
 {
	struct nfs_cb_data *data;

+	if (nfsfh->sr != NULL && count <= NFS_MAX_STREAMING_SIZE) {
+		int i, len, remaining, first_block, last_block;
+		unsigned char *buf, *pos;
+
+		/* track sequential access */
+		if (offset == nfsfh->sr->next_offset) {
+			nfsfh->sr->num_seq++;
+		} else {
+			if (nfsfh->sr->blocks[0].state != BSS_UNUSED) {
+				for (i = 0; i < nfsfh->sr->num_blocks; i++) {
+					nfsfh->sr->blocks[i].state = BSS_UNUSED;
+				}
+			}
+			nfsfh->sr->num_seq = 0;
+		}
+		nfsfh->sr->next_offset = offset + count;
+
+		if (nfsfh->sr->num_seq < 5) {
+			goto end_of_streaming;
+		}
+
+		/* If we do not have any cached data yet, reset buffer
+		 * offset to point slightly ahead of the current read.
+		 */
+		if (nfsfh->sr->blocks[0].state == BSS_UNUSED) {
+			nfsfh->sr->buf_offset = (offset / NFS_STREAM_BUF_SIZE + 1) * NFS_STREAM_BUF_SIZE ;
+		}
+
+		/* Prune head blocks we have read past */
+		while (nfsfh->sr->blocks[0].state != BSS_UNUSED &&
+			offset >= (nfsfh->sr->buf_offset + NFS_STREAM_BUF_SIZE)) {
+			unsigned char *ptr;
+
+			ptr = nfsfh->sr->blocks[0].ptr;
+			memmove(&nfsfh->sr->blocks[0], &nfsfh->sr->blocks[1],
+				(nfsfh->sr->num_blocks - 1)
+				* sizeof(struct nfs_streaming_block));
+			nfsfh->sr->buf_offset += NFS_STREAM_BUF_SIZE;
+			nfsfh->sr->blocks[nfsfh->sr->num_blocks - 1].state = BSS_UNUSED;
+			nfsfh->sr->blocks[nfsfh->sr->num_blocks - 1].ptr = ptr;
+		}
+
+		/* try to prefetch four more blocks */
+		prefetch_streaming_blocks(nfs, nfsfh, offset + count, 4);
+
+		/* can we service the request straight out of cache ? */
+		if (offset < nfsfh->sr->buf_offset) {
+			goto end_of_streaming;
+		}
+		first_block = (offset - nfsfh->sr->buf_offset) / NFS_STREAM_BUF_SIZE;
+		if (first_block >= nfsfh->sr->num_blocks) {
+			goto end_of_streaming;
+		}
+
+		if (offset + count > nfsfh->sr->buf_offset + nfsfh->sr->num_blocks * NFS_STREAM_BUF_SIZE) {
+			goto end_of_streaming;
+		}
+		last_block = (offset + count - nfsfh->sr->buf_offset - 1) / NFS_STREAM_BUF_SIZE;
+		if (last_block >= nfsfh->sr->num_blocks) {
+			goto end_of_streaming;
+		}
+		if (last_block < first_block) {
+			goto end_of_streaming;
+		}
+		for (i = first_block; i <= last_block; i++) {
+			if (nfsfh->sr->blocks[i].state != BSS_VALID) {
+				goto end_of_streaming;
+			}
+		}
+		if (first_block == last_block) {
+			if (update_pos) {
+				nfsfh->offset += count;
+			}
+			cb(count, nfs, &nfsfh->sr->blocks[first_block].ptr[offset % NFS_STREAM_BUF_SIZE], private_data);
+			return 0;
+		}
+
+		buf = malloc(count);
+		if (buf == NULL) {
+			goto end_of_streaming;
+		}
+		remaining = count;
+		pos = buf;
+		len = NFS_STREAM_BUF_SIZE - offset % NFS_STREAM_BUF_SIZE;
+		if (len > count) {
+			len = count;
+		}
+		memcpy(pos, &nfsfh->sr->blocks[first_block].ptr[offset % NFS_STREAM_BUF_SIZE], len);
+		remaining -= len;
+		pos += len;
+
+		for (i = first_block + 1; remaining; i++) {
+			len = (remaining >= NFS_STREAM_BUF_SIZE) ? NFS_STREAM_BUF_SIZE : remaining;
+			memcpy(pos, &nfsfh->sr->blocks[i].ptr[0], len);
+			remaining -= len;
+			pos += len;
+		}
+		if (update_pos) {
+			nfsfh->offset += count;
+		}
+		cb(count, nfs, buf, private_data);
+		free(buf);
+		return 0;
+	}
+end_of_streaming:
+
	data = malloc(sizeof(struct nfs_cb_data));
	if (data == NULL) {
		rpc_set_error(nfs->rpc, "out of memory: failed to allocate nfs_cb_data structure");
diff --git a/lib/socket.c b/lib/socket.c
index 3588246..41fb5b2 100644
--- a/lib/socket.c
+++ b/lib/socket.c
@@ -755,7 +755,7 @@ struct sockaddr *rpc_get_recv_sockaddr(struct rpc_context *rpc)
	return (struct sockaddr *)&rpc->udp_src;
 }

-int rpc_queue_length(struct rpc_context *rpc)
+int rpc_outqueue_length(struct rpc_context *rpc)
 {
	int i=0;
	struct rpc_pdu *pdu;
@@ -767,6 +767,19 @@ int rpc_queue_length(struct rpc_context *rpc)
		i++;
	}

+	return i;
+}
+
+int rpc_queue_length(struct rpc_context *rpc)
+{
+	int i=0;
+	struct rpc_pdu *pdu;
+	unsigned int n;
+
+	assert(rpc->magic == RPC_CONTEXT_MAGIC);
+
+	i = rpc_outqueue_length(rpc);
+
	for (n = 0; n < HASHES; n++) {
		struct rpc_queue *q = &rpc->waitpdu[n];

--
1.9.1


From 6f6832b6c19a26557883af924d7135f5ef87f45d Mon Sep 17 00:00:00 2001
From: Ronnie Sahlberg <ronniesahlberg@gmail.com>
Date: Sat, 7 Feb 2015 12:43:59 -0800
Subject: [PATCH 2/7] nfs-stream.c: a simple test tool to check performance
 sequential read mode

./nfs-stream <mfs-url> <bytes-per-second-to-read>

This tool is for testing sequential read mode.
It reads 32kbyte one block at a time using the sync API.
The idea is that when a nfs_[p]read() command is executed, we will once we
identify a sequential scan start issuing asynchronous commands in the
background to populate a readahead cache.

During read, we try to service the request immediately out of cache
and return immediately to the application. During read from cache we will also
process any to previous reads and use it to populate the cache. Also, as the
file offset grows, we will discard the already read blocks from the cache
and issue new asynchronous commands at the tail of the cache.

nfs_read() will when the cache is operating behave like :
  nfs_read() {
     ... process any previous reads and populate the cache ...
     ... send async command to replenish the tail of the cache ...
     return data from cache straigh back to application
  }

The test tool will try to read 32kb chunks at a given rate.
Once the test tool manages to service from cache  the read laency should drop
to <<1ms and the majority of the time spent will be in the sleep() between calls.
Once the latency is steady at <<1ms this is an indication that we now
service all reads out of cache instead of the network.
If the read latency remains <<1ms continously, without any spikes, it means that
we have been successfull in maintaining the asycntrhous tasks to replenish the cache.

Signed-off-by: Ronnie Sahlberg <ronniesahlberg@gmail.com>
---
 nfs-stream.c | 65 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 65 insertions(+)
 create mode 100644 nfs-stream.c

diff --git a/nfs-stream.c b/nfs-stream.c
new file mode 100644
index 0000000..5570cd6
--- /dev/null
+++ b/nfs-stream.c
@@ -0,0 +1,65 @@
+#include <fcntl.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <sys/stat.h>
+#include <sys/time.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include "nfsc/libnfs.h"
+
+int main(int argc, char *argv[])
+{
+	struct nfs_context *nfs;
+	struct nfs_url *url;
+	struct nfsfh *nfsfh = NULL;
+	struct nfs_stat_64 st;
+	uint64_t offset;
+	char buf[32768];
+	struct timeval t1, t2;
+	uint64_t delta, tpc;
+
+	nfs = nfs_init_context();
+	url = nfs_parse_url_full(nfs, argv[1]);
+	if (!url) {
+		fprintf(stderr, "Can not parse URL. %s\n",
+			nfs_get_error(nfs));
+		exit(1);
+	}
+	if (nfs_mount(nfs, url->server, url->path) != 0) {
+		fprintf(stderr, "Failed to mount nfs share : %s\n",
+			       nfs_get_error(nfs));
+		exit(1);
+	}
+	if (nfs_open(nfs, url->file, O_RDONLY, &nfsfh) != 0) {
+		fprintf(stderr, "Failed to open file %s: %s\n",
+			url->file,
+			nfs_get_error(nfs));
+		exit(1);
+	}
+	if (nfs_fstat64(nfs, nfsfh, &st)) {
+		fprintf(stderr, "Failed to stat file %s: %s\n",
+			url->file,
+			nfs_get_error(nfs));
+		exit(1);
+	}
+	printf("File size:%lld\n", (long long)st.nfs_size);
+	tpc = 1000000 / (strtol(argv[2], NULL, 10) / 32768);
+	printf("Read one 32kb chunk every %d us\n", (int)tpc);
+	for (offset = 0; offset < st.nfs_size; offset += 32768) {
+		gettimeofday(&t1, NULL);
+		nfs_read(nfs, nfsfh, 8192, buf);
+		gettimeofday(&t2, NULL);
+		delta = t2.tv_sec * 1000000LL + t2.tv_usec -
+		  t1.tv_sec * 1000000LL - t1.tv_usec;
+		printf("Read latency:%lld us\n", (long long)delta);
+		if (tpc > delta) {
+			printf("Sleep for %d us\n", (int)(tpc - delta));
+			usleep(tpc - delta);
+		}
+	}
+
+	nfs_close(nfs, nfsfh);
+	nfs_destroy_context(nfs);
+	nfs_destroy_url(url);
+	return 0;
+}
--
1.9.1


From 225e1c47727871c6ca74d6e3fef79ee6234923a1 Mon Sep 17 00:00:00 2001
From: Ronnie Sahlberg <ronniesahlberg@gmail.com>
Date: Sat, 7 Feb 2015 13:31:02 -0800
Subject: [PATCH 3/7] streaming: only try refilling 2 blocks at a time instead
 of 4

Signed-off-by: Ronnie Sahlberg <ronniesahlberg@gmail.com>
---
 lib/libnfs.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/lib/libnfs.c b/lib/libnfs.c
index 5fc921d..84e76b6 100644
--- a/lib/libnfs.c
+++ b/lib/libnfs.c
@@ -2448,8 +2448,8 @@ static int nfs_pread_async_internal(struct nfs_context *nfs, struct nfsfh *nfsfh
			nfsfh->sr->blocks[nfsfh->sr->num_blocks - 1].ptr = ptr;
		}

-		/* try to prefetch four more blocks */
-		prefetch_streaming_blocks(nfs, nfsfh, offset + count, 4);
+		/* try to prefetch to more blocks */
+		prefetch_streaming_blocks(nfs, nfsfh, offset + count, 2);

		/* can we service the request straight out of cache ? */
		if (offset < nfsfh->sr->buf_offset) {
--
1.9.1


From ceb35bb17425dda7408ae43ae80a997f4e1c1f95 Mon Sep 17 00:00:00 2001
From: Ronnie Sahlberg <ronniesahlberg@gmail.com>
Date: Sat, 7 Feb 2015 16:19:59 -0800
Subject: [PATCH 4/7] read 32kb at a time, not 8kb

crapadoodle,  if we measure 32kb blob read speed we should actually read
a 32kb blob too.   not a 8kb one.

Signed-off-by: Ronnie Sahlberg <ronniesahlberg@gmail.com>
---
 nfs-stream.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/nfs-stream.c b/nfs-stream.c
index 5570cd6..dd01218 100644
--- a/nfs-stream.c
+++ b/nfs-stream.c
@@ -47,13 +47,13 @@ int main(int argc, char *argv[])
	printf("Read one 32kb chunk every %d us\n", (int)tpc);
	for (offset = 0; offset < st.nfs_size; offset += 32768) {
		gettimeofday(&t1, NULL);
-		nfs_read(nfs, nfsfh, 8192, buf);
+		nfs_read(nfs, nfsfh, 32768, buf);
		gettimeofday(&t2, NULL);
		delta = t2.tv_sec * 1000000LL + t2.tv_usec -
		  t1.tv_sec * 1000000LL - t1.tv_usec;
		printf("Read latency:%lld us\n", (long long)delta);
		if (tpc > delta) {
-			printf("Sleep for %d us\n", (int)(tpc - delta));
+			//printf("Sleep for %d us\n", (int)(tpc - delta));
			usleep(tpc - delta);
		}
	}
--
1.9.1


From 5f5faa8cfb86057081ccb3e30f987ecdec40fa13 Mon Sep 17 00:00:00 2001
From: Ronnie Sahlberg <ronniesahlberg@gmail.com>
Date: Mon, 9 Feb 2015 20:46:25 -0800
Subject: [PATCH 5/7] prefetch: limit the amount of prefetches we have in
 flight to 2

Signed-off-by: Ronnie Sahlberg <ronniesahlberg@gmail.com>
---
 lib/libnfs.c | 16 +++++++++++++---
 nfs-stream.c |  7 +++++++
 2 files changed, 20 insertions(+), 3 deletions(-)

diff --git a/lib/libnfs.c b/lib/libnfs.c
index 84e76b6..929d3e0 100644
--- a/lib/libnfs.c
+++ b/lib/libnfs.c
@@ -2103,8 +2103,6 @@ static void nfs_open_cb(struct rpc_context *rpc, int status, void *command_data,
	nfsfh->fh = data->fh;
	data->fh.data.data_val = NULL;

-	nfs_set_streaming_mode(nfsfh, 200 * NFS_STREAM_BUF_SIZE);
-
	data->cb(0, nfs, nfsfh, data->private_data);
	free_nfs_cb_data(data);
 }
@@ -2374,12 +2372,24 @@ static void nfs_stream_cb(struct rpc_context *rpc, int status, void *command_dat

 static void prefetch_streaming_blocks(struct nfs_context *nfs, struct nfsfh *nfsfh, uint64_t next_offset, int num_blocks)
 {
-	int i;
+	int i, num_pending = 0;

	for (i = 0; i < nfsfh->sr->num_blocks && num_blocks; i++) {
		struct stream_cb_data *stream_data;
		READ3args args;

+		/*
+		 * BSS_PENDING means we have a request for prefetch in flight.
+		 * We don't want an unlimited amount of requests in flight
+		 * since it can cause wild latency spikes while initially
+		 * filling the prefetch buffer.
+		 */
+		if (nfsfh->sr->blocks[i].state == BSS_PENDING) {
+			num_pending++;
+		}
+		if (num_pending >= num_blocks) {
+			continue;
+		}
		if (nfsfh->sr->blocks[i].state != BSS_UNUSED) {
			continue;
		}
diff --git a/nfs-stream.c b/nfs-stream.c
index dd01218..f5a1b0a 100644
--- a/nfs-stream.c
+++ b/nfs-stream.c
@@ -18,6 +18,11 @@ int main(int argc, char *argv[])
	struct timeval t1, t2;
	uint64_t delta, tpc;

+	if (argc != 3) {
+		fprintf(stderr, "Usage: nfs-stream <nfs-url> <bytes-per-second>\n");
+		exit(1);
+	}
+
	nfs = nfs_init_context();
	url = nfs_parse_url_full(nfs, argv[1]);
	if (!url) {
@@ -36,6 +41,8 @@ int main(int argc, char *argv[])
			nfs_get_error(nfs));
		exit(1);
	}
+	nfs_set_streaming_mode(nfsfh, 5 * 1024 * 1024);
+
	if (nfs_fstat64(nfs, nfsfh, &st)) {
		fprintf(stderr, "Failed to stat file %s: %s\n",
			url->file,
--
1.9.1


From 503492873f27cefc3bfb368a96c4c7e1c99b303f Mon Sep 17 00:00:00 2001
From: Ronnie Sahlberg <ronniesahlberg@gmail.com>
Date: Tue, 10 Feb 2015 16:40:53 -0800
Subject: [PATCH 6/7] streaming mode: wait until we have 10 sequential reads
 before we prefetch

Signed-off-by: Ronnie Sahlberg <ronniesahlberg@gmail.com>
---
 lib/libnfs.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/lib/libnfs.c b/lib/libnfs.c
index 929d3e0..53b71fd 100644
--- a/lib/libnfs.c
+++ b/lib/libnfs.c
@@ -2433,7 +2433,7 @@ static int nfs_pread_async_internal(struct nfs_context *nfs, struct nfsfh *nfsfh
		}
		nfsfh->sr->next_offset = offset + count;

-		if (nfsfh->sr->num_seq < 5) {
+		if (nfsfh->sr->num_seq < 10) {
			goto end_of_streaming;
		}

--
1.9.1


From 55a673ae81514f109553d36b71647e8c334f8d81 Mon Sep 17 00:00:00 2001
From: Ronnie Sahlberg <ronniesahlberg@gmail.com>
Date: Wed, 11 Feb 2015 01:25:05 -0800
Subject: [PATCH 7/7] nfs-stream.c: move this tool to the examples directory

Signed-off-by: Ronnie Sahlberg <ronniesahlberg@gmail.com>
---
 examples/nfs-stream.c | 72 +++++++++++++++++++++++++++++++++++++++++++++++++++
 nfs-stream.c          | 72 ---------------------------------------------------
 2 files changed, 72 insertions(+), 72 deletions(-)
 create mode 100644 examples/nfs-stream.c
 delete mode 100644 nfs-stream.c

diff --git a/examples/nfs-stream.c b/examples/nfs-stream.c
new file mode 100644
index 0000000..f5a1b0a
--- /dev/null
+++ b/examples/nfs-stream.c
@@ -0,0 +1,72 @@
+#include <fcntl.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <sys/stat.h>
+#include <sys/time.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include "nfsc/libnfs.h"
+
+int main(int argc, char *argv[])
+{
+	struct nfs_context *nfs;
+	struct nfs_url *url;
+	struct nfsfh *nfsfh = NULL;
+	struct nfs_stat_64 st;
+	uint64_t offset;
+	char buf[32768];
+	struct timeval t1, t2;
+	uint64_t delta, tpc;
+
+	if (argc != 3) {
+		fprintf(stderr, "Usage: nfs-stream <nfs-url> <bytes-per-second>\n");
+		exit(1);
+	}
+
+	nfs = nfs_init_context();
+	url = nfs_parse_url_full(nfs, argv[1]);
+	if (!url) {
+		fprintf(stderr, "Can not parse URL. %s\n",
+			nfs_get_error(nfs));
+		exit(1);
+	}
+	if (nfs_mount(nfs, url->server, url->path) != 0) {
+		fprintf(stderr, "Failed to mount nfs share : %s\n",
+			       nfs_get_error(nfs));
+		exit(1);
+	}
+	if (nfs_open(nfs, url->file, O_RDONLY, &nfsfh) != 0) {
+		fprintf(stderr, "Failed to open file %s: %s\n",
+			url->file,
+			nfs_get_error(nfs));
+		exit(1);
+	}
+	nfs_set_streaming_mode(nfsfh, 5 * 1024 * 1024);
+
+	if (nfs_fstat64(nfs, nfsfh, &st)) {
+		fprintf(stderr, "Failed to stat file %s: %s\n",
+			url->file,
+			nfs_get_error(nfs));
+		exit(1);
+	}
+	printf("File size:%lld\n", (long long)st.nfs_size);
+	tpc = 1000000 / (strtol(argv[2], NULL, 10) / 32768);
+	printf("Read one 32kb chunk every %d us\n", (int)tpc);
+	for (offset = 0; offset < st.nfs_size; offset += 32768) {
+		gettimeofday(&t1, NULL);
+		nfs_read(nfs, nfsfh, 32768, buf);
+		gettimeofday(&t2, NULL);
+		delta = t2.tv_sec * 1000000LL + t2.tv_usec -
+		  t1.tv_sec * 1000000LL - t1.tv_usec;
+		printf("Read latency:%lld us\n", (long long)delta);
+		if (tpc > delta) {
+			//printf("Sleep for %d us\n", (int)(tpc - delta));
+			usleep(tpc - delta);
+		}
+	}
+
+	nfs_close(nfs, nfsfh);
+	nfs_destroy_context(nfs);
+	nfs_destroy_url(url);
+	return 0;
+}
diff --git a/nfs-stream.c b/nfs-stream.c
deleted file mode 100644
index f5a1b0a..0000000
--- a/nfs-stream.c
+++ /dev/null
@@ -1,72 +0,0 @@
-#include <fcntl.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <sys/stat.h>
-#include <sys/time.h>
-#include <sys/types.h>
-#include <unistd.h>
-#include "nfsc/libnfs.h"
-
-int main(int argc, char *argv[])
-{
-	struct nfs_context *nfs;
-	struct nfs_url *url;
-	struct nfsfh *nfsfh = NULL;
-	struct nfs_stat_64 st;
-	uint64_t offset;
-	char buf[32768];
-	struct timeval t1, t2;
-	uint64_t delta, tpc;
-
-	if (argc != 3) {
-		fprintf(stderr, "Usage: nfs-stream <nfs-url> <bytes-per-second>\n");
-		exit(1);
-	}
-
-	nfs = nfs_init_context();
-	url = nfs_parse_url_full(nfs, argv[1]);
-	if (!url) {
-		fprintf(stderr, "Can not parse URL. %s\n",
-			nfs_get_error(nfs));
-		exit(1);
-	}
-	if (nfs_mount(nfs, url->server, url->path) != 0) {
-		fprintf(stderr, "Failed to mount nfs share : %s\n",
-			       nfs_get_error(nfs));
-		exit(1);
-	}
-	if (nfs_open(nfs, url->file, O_RDONLY, &nfsfh) != 0) {
-		fprintf(stderr, "Failed to open file %s: %s\n",
-			url->file,
-			nfs_get_error(nfs));
-		exit(1);
-	}
-	nfs_set_streaming_mode(nfsfh, 5 * 1024 * 1024);
-
-	if (nfs_fstat64(nfs, nfsfh, &st)) {
-		fprintf(stderr, "Failed to stat file %s: %s\n",
-			url->file,
-			nfs_get_error(nfs));
-		exit(1);
-	}
-	printf("File size:%lld\n", (long long)st.nfs_size);
-	tpc = 1000000 / (strtol(argv[2], NULL, 10) / 32768);
-	printf("Read one 32kb chunk every %d us\n", (int)tpc);
-	for (offset = 0; offset < st.nfs_size; offset += 32768) {
-		gettimeofday(&t1, NULL);
-		nfs_read(nfs, nfsfh, 32768, buf);
-		gettimeofday(&t2, NULL);
-		delta = t2.tv_sec * 1000000LL + t2.tv_usec -
-		  t1.tv_sec * 1000000LL - t1.tv_usec;
-		printf("Read latency:%lld us\n", (long long)delta);
-		if (tpc > delta) {
-			//printf("Sleep for %d us\n", (int)(tpc - delta));
-			usleep(tpc - delta);
-		}
-	}
-
-	nfs_close(nfs, nfsfh);
-	nfs_destroy_context(nfs);
-	nfs_destroy_url(url);
-	return 0;
-}
--
1.9.1
